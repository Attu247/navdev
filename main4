from flask import Flask, request, jsonify
from ultralytics import YOLO
from gtts import gTTS
import os
import google.generativeai as genai

# Initialize Flask app
app = Flask(__name__)

# Load YOLO model
model = YOLO('yolov8n.pt')  # Load pretrained YOLOv8 model

# Configure audio output to AUX
os.system("amixer cset numid=3 1")  # Set audio output to AUX (3.5mm jack)

# Gemini API key (set your actual key here)
gem_api_key = "AIzaSyC_Fe1avLOL7x-_B08A4PKaOHkSh8DUbXI"

# Configure Gemini API
genai.configure(api_key=gem_api_key)

# Function to capture and analyze image
def capture_and_analyze():
    camera_image_path = '/home/derpzyz/captured_image.jpg'
    
    # Capture an image from the Raspberry Pi Camera
    os.system(f"libcamera-still -o {camera_image_path} --nopreview")
    
    # Run YOLO detection
    results = model(camera_image_path)  # Predict on the captured image
    
    # Extract predictions and generate a description
    detected_objects = []
    for result in results:
        for obj in result.boxes:
            label = result.names[int(obj.cls)]  # Get the class label
            confidence = float(obj.conf)  # Convert confidence to a float
            detected_objects.append(f"{label} ({confidence:.2f})")  # Format as a string

    # Combine results into a text description
    if detected_objects:
        description = "Detected: " + ", ".join(detected_objects)
    else:
        description = "No objects detected in the scene."

    # Upload the captured image for analysis
    sample_file = genai.upload_file(path=camera_image_path, display_name="sidewalk")
    
    # Define the prompt for Gemini (analysis description)
    gem_prompt = """
    Act as a Safety Inspector. Analyze the visual scene and provide a clear, factual description with a focus on identifying potential hazards or obstacles that could impact someone walking through the area...
    """
    
    # Call Gemini API to generate content based on the analysis
    gem_model = genai.GenerativeModel("gemini-1.5-flash")
    response = gem_model.generate_content([sample_file, gem_prompt])

    # Convert the Gemini response to speech
    tts = gTTS(text=response.text, lang='en')
    speech_output_path = '/home/derpzyz/navigation_output.mp3'
    tts.save(speech_output_path)

    # Play the speech output through AUX
    os.system(f"mpg321 {speech_output_path}")
    
    return description

# Flask routes for web control
@app.route('/command', methods=['POST'])
def handle_command():
    data = request.json
    if 'command' not in data:
        return jsonify({"error": "No command provided"}), 400
    
    command = data['command']
    if command == "capture_and_analyze":
        result = capture_and_analyze()
        return jsonify({"status": "success", "result": result})
    else:
        return jsonify({"error": "Unknown command"}), 400

# Start the Flask server
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
